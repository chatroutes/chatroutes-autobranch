# GPU vs CPU Cheat Sheet - Quick Reference

## âš¡ Quick Answer

**Q: Does inference require GPU?**
**A: No, but GPU is 20-40x faster.**

---

## ğŸ“Š Speed Comparison

| Model | CPU | GPU Free (T4) | GPU Pro (V100) |
|-------|-----|---------------|----------------|
| llama3.1:8b | 40s | 1-3s | 0.5-1s |
| qwen3:14b | 80s | 3-5s | 1-2s |
| gpt-oss:20b | 120s | 5-8s | 2-3s |
| **Embeddings** (1000 texts) | 10s | 2s | 1s |

---

## ğŸ’° Cost Comparison

| Setup | Cost | Best For |
|-------|------|----------|
| **CPU (Local)** | $0 | Development, unlimited use |
| **GPU (Free Colab)** | $0 | Quick demos (~15 hrs/week) |
| **GPU (Colab Pro)** | $10/mo | Regular use (~100 hrs/mo) |
| **GPU (Colab Pro+)** | $50/mo | Heavy use (~500 hrs/mo) |

---

## ğŸ¯ Decision Matrix

### Use CPU If:
- âœ… Learning/testing
- âœ… No time pressure
- âœ… Unlimited usage needed
- âœ… $0 budget

### Use GPU If:
- âš¡ Need fast iteration
- âš¡ Running many experiments
- âš¡ Production demos
- âš¡ Time > Money

---

## ğŸ”„ Local vs Colab

| Feature | Local (CPU) | Colab (CPU) | Colab (GPU) |
|---------|-------------|-------------|-------------|
| **Speed** | 40s/response | 40s/response | 1-3s/response |
| **Cost** | $0 | $0 | $0-50/mo |
| **Setup** | One-time | Every session | Every session |
| **Storage** | Persistent | Ephemeral | Ephemeral |
| **Limit** | None | None | GPU hours |

---

## ğŸ“¥ Model Downloads

### Local
```bash
ollama pull llama3.1:8b  # Once
# âœ… Persists forever
```

### Colab
```python
!ollama pull llama3.1:8b  # Every session
# âŒ Lost after ~12-24 hours
# ğŸ”„ Re-download: 2-5 minutes
```

**Solution**: Cache to Google Drive (see COLAB_GUIDE.md)

---

## â±ï¸ Total Runtime (4 Scenarios)

| Setup | Generation | Pipeline | Total |
|-------|-----------|----------|-------|
| **CPU** | 35 min | 1 min | ~36 min |
| **GPU** | 2 min | 0.5 min | ~2.5 min |

**Speedup**: ~14x faster with GPU

---

## ğŸš€ Quick Start Commands

### Local (CPU)
```bash
# One-time setup
ollama pull llama3.1:8b
pip install chatroutes-autobranch sentence-transformers

# Run anytime
python examples/creative_writting_usage.py
```

### Colab (CPU)
```python
# Every session
!curl -fsSL https://ollama.com/install.sh | sh
!ollama serve &
!ollama pull llama3.1:8b
!pip install chatroutes-autobranch sentence-transformers
!python examples/creative_writting_usage.py
```

### Colab (GPU)
```python
# Same as CPU, but:
Runtime â†’ Change runtime type â†’ GPU (T4)
# Then run same commands
# âš¡ 20-40x faster!
```

---

## ğŸ’¡ Optimization Tips

### Faster Downloads
```python
MODEL = "llama3.1:8b"  # 4.9 GB (fastest)
# vs
MODEL = "qwen3:14b"    # 9.3 GB
MODEL = "gpt-oss:20b"  # 13 GB
```

### Faster Testing
```python
n=5  # Generate 5 candidates instead of 10-15
# Cuts time in half
```

### Cache Models (Colab)
```python
from google.colab import drive
drive.mount('/content/drive')
os.environ['HF_HOME'] = '/content/drive/MyDrive/cache'
# âœ… Persists across sessions
```

---

## ğŸ› Common Issues

### "Too slow on CPU"
â†’ Expected! 40s/response is normal
â†’ Use GPU for speed
â†’ Or use smaller model

### "GPU quota exceeded"
â†’ Switch to CPU (free, unlimited)
â†’ Or upgrade to Colab Pro

### "Model not found"
â†’ Re-download: `ollama pull MODEL_NAME`
â†’ Models don't persist in Colab

### "Out of memory"
â†’ Use smaller model: `llama3.1:8b`
â†’ Restart runtime
â†’ Upgrade to Colab Pro

---

## ğŸ“Š Real-World Performance (Your Tests)

**Your Machine (CPU)**:
- llama3.1:8b: ~43s per response âœ…
- Total time: 35-40 minutes âœ…
- 100% FREE âœ…

**Expected on GPU**:
- llama3.1:8b: ~1-3s per response âš¡
- Total time: 5-10 minutes âš¡
- Cost: $0-10/month ğŸ’°

---

## ğŸ“ Recommendation

**For Learning** â†’ Start with CPU (local or Colab)
- âœ… Free
- âœ… Unlimited
- âœ… No setup hassle

**For Production** â†’ Use GPU (Colab Pro or Cloud)
- âš¡ Fast
- âš¡ Efficient
- âš¡ Worth the cost

---

## ğŸ“š Files Created

1. **`notebooks/creative_writing_colab.ipynb`** - Full Colab notebook
2. **`COLAB_GUIDE.md`** - 60+ page guide
3. **`COLAB_NOTEBOOK_README.md`** - Quick start
4. **`GPU_VS_CPU_CHEATSHEET.md`** - This file

---

## âœ… Bottom Line

| Question | Answer |
|----------|--------|
| **Need GPU?** | No, but 20-40x faster |
| **CPU cost?** | $0 forever |
| **GPU cost?** | $0-50/month |
| **Best for learning?** | CPU |
| **Best for production?** | GPU |
| **Models persist in Colab?** | No (re-download each session) |
| **Colab setup time?** | 6-7 minutes |
| **Total runtime (CPU)?** | 35-40 minutes |
| **Total runtime (GPU)?** | 5-10 minutes |

**Verdict**: Start with CPU (free), upgrade to GPU when speed matters!

---

Made with â¤ï¸ using ChatRoutes AutoBranch
