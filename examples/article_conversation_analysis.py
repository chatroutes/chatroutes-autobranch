"""
Complete Analysis of Article Planning Conversation

This example demonstrates the full power of hybrid + LLM branch detection
on your actual conversation about planning the AI/human value article series.

Shows:
1. Explicit branches (marked decision points)
2. Semantic branches (automatic pattern detection)
3. LLM branches (Llama 3 for complex/implicit cases)
4. Visual summary and recommendations
"""

import sys
from chatroutes_autobranch.branch_detection import (
    ConversationFlowAnalyzer,
    LLMBranchParser,
    ConversationTurn,
)
from chatroutes_autobranch.core.embeddings import DummyEmbeddingProvider

try:
    import ollama
    OLLAMA_AVAILABLE = True
except ImportError:
    OLLAMA_AVAILABLE = False


def print_section(title: str, char: str = "="):
    """Print a section header."""
    print("\n" + char * 80)
    print(title)
    print(char * 80)


def main():
    print_section("ARTICLE CONVERSATION ANALYSIS: Three-Way Detection")

    # ========================================================================
    # Your Actual Conversation (from ChatGPT)
    # ========================================================================

    conversation = [
        ConversationTurn(
            id="1",
            speaker="user",
            content="currently llm search web to gather facts and details. with the growing number of llm users what if people stop creating those websites. how will llm find details about new things ideas etc."
        ),
        ConversationTurn(
            id="2",
            speaker="user",
            content="most of the content these days is being generated by llm, so we are loosing humans in this loop. humans are no longer incetivised to create own information, they use llm"
        ),
        ConversationTurn(
            id="3",
            speaker="user",
            content="challenged is how to verify if a content is purely and honestly created by humans"
        ),
        ConversationTurn(
            id="4",
            speaker="assistant",
            content="Philosophical Layer: What counts as human? spectrum of authorship: Human-origin, Human + AI co-creation, AI-origin"
        ),
        ConversationTurn(
            id="5",
            speaker="user",
            content="yes i would like to know more about the origin and research around it"
        ),
        ConversationTurn(
            id="6",
            speaker="user",
            content="yes i would like to write an article based on the available credible research on this topic and especially ideas how can humans keep their value."
        ),
        ConversationTurn(
            id="7",
            speaker="user",
            content='here is my rough draft: "With all the hype of Gen AI these days and reading daily about many layoffs or restructuring many of us are wondering what is our future?"'
        ),
        # ADD EXPLICIT BRANCH MARKER HERE
        ConversationTurn(
            id="7a",
            speaker="user",
            content="""BRANCH: Article Focus Decision

After exploring the topic, I need to decide the main direction:

OPTIONS:
1. Philosophical - Deep dive into meaning of work, human value, authorship spectrum
2. Practical - Focus on specific professions, actionable advice, skills to learn
3. Historical - Analyze labor transitions (farm‚Üífactory‚Üíoffice‚ÜíAI), pattern extraction
4. Comprehensive - Multi-article series covering all angles

Which approach will provide the most value to readers?"""
        ),
        ConversationTurn(
            id="8",
            speaker="user",
            content="i want to add historical references, studies, graphs and show some examples from past where machines enabled humans to get better at things."
        ),
        ConversationTurn(
            id="9",
            speaker="user",
            content="so if you are typical office worker who creates reports, spreadsheets, budgets and you have analytical skills today to certain job what should he do."
        ),
        ConversationTurn(
            id="10",
            speaker="user",
            content="how this wave of labor changed from farmlands to factories to officies"
        ),
        ConversationTurn(
            id="11",
            speaker="user",
            content="so let's take some examples of some concrete roles and see how those people should change for future"
        ),
        ConversationTurn(
            id="12",
            speaker="user",
            content="lets focus on those traditioanal roles of accountant, lawyer, doctors etc. should they still study what they study today"
        ),
        ConversationTurn(
            id="13",
            speaker="user",
            content="ok now i am thinking to divide this into multiple articles and start with the definition of creativity, human creativity, meaning of work, creation of value and how value creation is changing."
        ),
        ConversationTurn(
            id="14",
            speaker="user",
            content="What should write for part 1. I need to back my words with different writers book, trusted data source. Article shows the breadth and width from different angles."
        ),
    ]

    # ========================================================================
    # DETECTION #1: Hybrid (Explicit + Semantic)
    # ========================================================================

    print_section("PHASE 1: Hybrid Detection (Explicit + Semantic)", "-")
    print("\nRunning hybrid analyzer...")
    print("- Explicit detection: Looking for BRANCH:, OPTIONS: markers")
    print("- Semantic detection: Topic shifts, decision points, Q‚ÜíA transitions")

    analyzer = ConversationFlowAnalyzer(
        embedding_provider=DummyEmbeddingProvider(dimension=384, seed=42),
        topic_shift_threshold=0.6,
        enable_explicit=True,
        enable_semantic=True,
    )

    results = analyzer.analyze(conversation)

    print(f"\n‚úì Analysis complete!")
    print(f"  Explicit branches: {len(results['explicit_branches'])}")
    print(f"  Semantic branches: {len(results['semantic_branches'])}")

    # Show explicit branches
    if results['explicit_branches']:
        print_section("Explicit Branches Detected", "-")
        for i, branch in enumerate(results['explicit_branches'], 1):
            print(f"\n{i}. {branch.type.upper()} at turn {branch.meta.get('turn_id', '?')}")
            print(f"   Confidence: {branch.meta.get('confidence', 1.0):.2f}")
            print(f"   Options ({branch.option_count}):")
            for opt in branch.options:
                print(f"     ‚Ä¢ {opt.label}")

    # Show semantic branches
    if results['semantic_branches']:
        print_section("Semantic Branches Detected", "-")
        for i, branch in enumerate(results['semantic_branches'], 1):
            print(f"\n{i}. {branch.branch_type.upper()} at turn {branch.turn_id}")
            print(f"   Confidence: {branch.confidence:.2f}")
            print(f"   Description: {branch.description}")
            print(f"   Before: {branch.context_before[:60]}...")
            print(f"   After: {branch.context_after[:60]}...")

    # ========================================================================
    # DETECTION #2: Llama 3 (LLM-Powered)
    # ========================================================================

    llm_branches = []

    if OLLAMA_AVAILABLE:
        print_section("PHASE 2: Llama 3 Detection (LLM-Powered)", "-")
        print("\nCalling Llama 3 for advanced semantic analysis...")
        print("This will detect implicit/complex branches that patterns miss...")

        def llama3(prompt: str) -> str:
            try:
                response = ollama.chat(
                    model='llama3',
                    messages=[{'role': 'user', 'content': prompt}],
                    options={'temperature': 0.1, 'num_predict': 2000}
                )
                return response['message']['content']
            except Exception as e:
                return f"ERROR: {str(e)}"

        parser = LLMBranchParser(llm=llama3)

        # Convert conversation to text
        conversation_text = "\n\n".join([
            f"[Turn {turn.id}] {turn.speaker}: {turn.content}"
            for turn in conversation
            if turn.id != "7a"  # Skip the explicit marker for LLM analysis
        ])

        print("\nAnalyzing conversation (this may take 5-10 seconds)...")
        llm_branches, metadata = parser.parse_with_confidence(conversation_text)

        if metadata['success']:
            print(f"‚úì Llama 3 analysis complete!")
            print(f"  Branches detected: {len(llm_branches)}")

            if llm_branches:
                print_section("LLM Branches Detected", "-")
                for i, branch in enumerate(llm_branches, 1):
                    print(f"\n{i}. {branch.type.upper()} (ID: {branch.id})")
                    print(f"   Options ({len(branch.options)}):")
                    for opt in branch.options:
                        print(f"     ‚Ä¢ {opt.label}")
                    if branch.context:
                        print(f"   Context: {branch.context[:80]}...")
        else:
            print(f"‚ö† Llama 3 failed: {metadata.get('error', 'Unknown error')}")

    else:
        print_section("PHASE 2: Llama 3 Detection (SKIPPED)", "-")
        print("\n‚ö† Ollama not installed. Install to enable Llama 3 detection:")
        print("  1. Install Ollama: https://ollama.ai")
        print("  2. Run: ollama pull llama3")
        print("  3. Install client: pip install ollama")

    # ========================================================================
    # COMBINED RESULTS
    # ========================================================================

    print_section("COMBINED RESULTS: All Detection Methods")

    total_branches = (
        len(results['explicit_branches']) +
        len(results['semantic_branches']) +
        len(llm_branches)
    )

    print(f"\nTotal branches detected: {total_branches}")
    print(f"  ‚Ä¢ Explicit (marked): {len(results['explicit_branches'])}")
    print(f"  ‚Ä¢ Semantic (patterns): {len(results['semantic_branches'])}")
    print(f"  ‚Ä¢ LLM (Llama 3): {len(llm_branches)}")

    # ========================================================================
    # CONVERSATION FLOW MAP
    # ========================================================================

    print_section("CONVERSATION FLOW MAP")

    print("""
Turn 1-3:  LLM Data Problem ‚Üí Human Value Crisis
           ‚îî‚îÄ [SEMANTIC] Topic: Information ecosystem concerns

Turn 4-5:  Philosophical Exploration ‚Üí Research Interest
           ‚îî‚îÄ [SEMANTIC] Pattern: Curiosity about authorship spectrum

Turn 6-7:  Research Interest ‚Üí Article Commitment
           ‚îî‚îÄ [SEMANTIC] Decision Point: "I would like to write"

Turn 7a:   EXPLICIT DECISION POINT
           ‚îî‚îÄ [EXPLICIT] Branch: Article Focus (4 options)
              1. Philosophical
              2. Practical
              3. Historical
              4. Comprehensive (multi-article)

Turn 8-12: Scope Exploration ‚Üí Profession Focus
           ‚îî‚îÄ [SEMANTIC] Refinement: Adding concrete examples

Turn 13:   MAJOR PIVOT: One Article ‚Üí Multi-Article Series
           ‚îî‚îÄ [SEMANTIC] Decision: Comprehensive approach chosen
           ‚îî‚îÄ Structure: Creativity ‚Üí Professions ‚Üí Companies

Turn 14:   Implementation Details ‚Üí Source Requirements
           ‚îî‚îÄ Focus: Part 1 preparation
""")

    # ========================================================================
    # ANALYSIS & RECOMMENDATIONS
    # ========================================================================

    print_section("ANALYSIS & RECOMMENDATIONS")

    print("""
üéØ KEY INSIGHTS FROM BRANCH ANALYSIS:

1. CONVERSATION EVOLUTION:
   - Started broad: LLM ecosystem problem
   - Narrowed focus: Human value preservation
   - Expanded scope: Multi-article comprehensive series
   - Current state: Planning Article 1 details

2. DECISION POINTS IDENTIFIED:
   - Turn 7a: EXPLICIT choice of article direction (4 options)
   - Turn 13: IMPLICIT decision to go comprehensive
   - Multiple SEMANTIC shifts as topic evolved

3. BRANCH STRUCTURE:
   Your conversation created a decision tree:

   Root: LLM Problem
   ‚îú‚îÄ Branch 1: Focus on philosophy vs practical
   ‚îÇ  ‚îî‚îÄ Resolved: Want both
   ‚îú‚îÄ Branch 2: One article vs multiple
   ‚îÇ  ‚îî‚îÄ Resolved: Multiple (comprehensive)
   ‚îî‚îÄ Branch 3: Article 1 content
      ‚îî‚îÄ Active: Creativity, meaning, value creation

üìù RECOMMENDATIONS FOR YOUR ARTICLE SERIES:

ARTICLE 1: "Creativity & Value in the AI Age"
   - Define creativity (multiple frameworks)
   - Meaning of work through history
   - Value creation evolution (land‚Üílabor‚Üíknowledge‚Üí?)
   - Historical patterns: Farm‚ÜíFactory‚ÜíOffice‚ÜíAI

   Sources to include:
   - Csikszentmihalyi: Flow & creativity
   - Schumpeter: Creative destruction
   - Arendt: The Human Condition (work philosophy)
   - BLS data: Labor transitions
   - McKinsey: AI & labor market reports

ARTICLE 2: "Professions in Transition"
   - Accountants, lawyers, doctors case studies
   - What AI automates vs augments
   - New roles emerging
   - Skills to develop

   Sources:
   - Professional association reports
   - MIT/Oxford AI studies
   - Early AI adoption case studies

ARTICLE 3: "The Future Company"
   - Traditional vs AI-native organizations
   - Work simulation examples
   - Decision-making changes
   - New organizational structures

üîß TECHNICAL IMPLEMENTATION TIPS:

1. USE EXPLICIT MARKERS in future conversations:
   When you have important decision points, mark them:

   BRANCH: Article Structure
   OPTIONS:
   1. Linear narrative
   2. Problem-solution format
   3. Historical analysis

   This ensures 100% detection.

2. HYBRID DETECTION catches most patterns automatically
   - Topic shifts: Detected ‚úì
   - Decision points: Detected ‚úì
   - Question‚ÜíAction: Detected ‚úì

3. ADD LLAMA 3 for complex/ambiguous branches
   - Implicit reasoning
   - Multi-layered decisions
   - Narrative branches

üìä NEXT STEPS:

1. ‚úì Use this analysis to structure Article 1
2. Create explicit branch markers for research directions
3. Use semantic detection to track topic evolution
4. Use Llama 3 for ambiguous conceptual branches
5. Build conversation flow map as you write

üí° INSIGHT:
Your conversation showed a natural progression from problem‚Üíresearch‚Üíaction‚Üíplanning.
The branch detection reveals decision points you might not have consciously noticed:
- Turn 6‚Üí7: Curiosity ‚Üí Commitment
- Turn 12‚Üí13: Narrow ‚Üí Comprehensive
- Turn 13‚Üí14: Structure ‚Üí Implementation

These are the key moments where your article series was born!
""")

    print_section("END OF ANALYSIS", "=")
    print("\nFiles to explore:")
    print("  ‚Ä¢ examples/llama3_simple.py - Basic Llama 3 usage")
    print("  ‚Ä¢ examples/llama3_debug.py - Debug Llama 3 responses")
    print("  ‚Ä¢ examples/analyze_conversation_hybrid.py - Hybrid demo")
    print("  ‚Ä¢ docs/HYBRID_BRANCH_DETECTION.md - Full documentation")
    print("  ‚Ä¢ docs/LLAMA3_QUICKSTART.md - Llama 3 guide")


if __name__ == "__main__":
    main()
