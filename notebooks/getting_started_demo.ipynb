{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro"
      },
      "source": [
        "# ChatRoutes AutoBranch - Getting Started Demo\n",
        "\n",
        "**Intelligent branch exploration for LLM-powered applications**\n",
        "\n",
        "[![PyPI version](https://badge.fury.io/py/chatroutes-autobranch.svg)](https://badge.fury.io/py/chatroutes-autobranch)\n",
        "[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n",
        "[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\n",
        "\n",
        "---\n",
        "\n",
        "## What is ChatRoutes AutoBranch?\n",
        "\n",
        "ChatRoutes AutoBranch helps you:\n",
        "- üéØ **Select the best responses** from multiple LLM outputs (beam search)\n",
        "- üåà **Ensure diversity** in responses (avoid repetition)\n",
        "- üõë **Know when to stop** exploring (entropy-based convergence)\n",
        "- üí∞ **Control costs** with budget management (tokens, time, nodes)\n",
        "\n",
        "Perfect for:\n",
        "- Tree-of-thought reasoning\n",
        "- Multi-agent systems\n",
        "- Creative writing\n",
        "- Question answering\n",
        "- Any LLM application that explores multiple paths\n",
        "\n",
        "---\n",
        "\n",
        "## This Demo\n",
        "\n",
        "In this notebook, we'll cover:\n",
        "1. Installation\n",
        "2. Basic beam search\n",
        "3. Scoring strategies\n",
        "4. Novelty filtering\n",
        "5. Complete pipeline example\n",
        "\n",
        "**Time**: ~5 minutes  \n",
        "**Level**: Beginner-friendly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "installation"
      },
      "source": [
        "## Step 1: Installation\n",
        "\n",
        "Install ChatRoutes AutoBranch from PyPI:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "!pip install -q chatroutes-autobranch\n",
        "print(\"‚úÖ Installation complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imports"
      },
      "source": [
        "## Step 2: Import the Library\n",
        "\n",
        "Let's import the key components:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports_code"
      },
      "outputs": [],
      "source": [
        "from chatroutes_autobranch import (\n",
        "    # Core components\n",
        "    BranchSelector,\n",
        "    BeamSelector,\n",
        "    Candidate,\n",
        "    ScoredCandidate,\n",
        "    \n",
        "    # Scoring\n",
        "    CompositeScorer,\n",
        "    \n",
        "    # Novelty filtering\n",
        "    CosineNoveltyFilter,\n",
        "    MMRNoveltyFilter,\n",
        "    \n",
        "    # Budget management\n",
        "    Budget,\n",
        "    BudgetManager,\n",
        "    \n",
        "    # Utilities\n",
        "    DummyEmbeddingProvider,\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Imports successful!\")\n",
        "print(\"\\nKey components:\")\n",
        "print(\"  ‚Ä¢ BranchSelector - Main orchestrator\")\n",
        "print(\"  ‚Ä¢ BeamSelector - Keeps top-K candidates\")\n",
        "print(\"  ‚Ä¢ Candidate - Represents a branch/response\")\n",
        "print(\"  ‚Ä¢ CompositeScorer - Combines multiple scoring strategies\")\n",
        "print(\"  ‚Ä¢ NoveltyFilters - Remove similar/redundant responses\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "example1"
      },
      "source": [
        "## Example 1: Basic Beam Search\n",
        "\n",
        "Let's start with a simple example: selecting the top 3 responses from 5 candidates.\n",
        "\n",
        "**Scenario**: You asked an LLM to generate story openings, and got 5 responses. You want to keep only the best 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "example1_code"
      },
      "outputs": [],
      "source": [
        "# Step 1: Create a simple beam selector (keep top 3)\n",
        "beam = BeamSelector(k=3)\n",
        "\n",
        "# Step 2: Create the main selector\n",
        "selector = BranchSelector(beam_selector=beam)\n",
        "\n",
        "# Step 3: Define your candidates\n",
        "# In real use, these would come from your LLM with logprobs/scores\n",
        "parent = Candidate(\n",
        "    id=\"prompt\",\n",
        "    text=\"Write a story opening about a detective\",\n",
        "    meta={\"logprobs\": -0.1}\n",
        ")\n",
        "\n",
        "candidates = [\n",
        "    Candidate(id=\"c1\", text=\"Detective Sarah Chen walked into the dimly lit office...\", meta={\"logprobs\": -0.5}),\n",
        "    Candidate(id=\"c2\", text=\"The rain hammered against the window as Detective Miller reviewed the case...\", meta={\"logprobs\": -0.3}),\n",
        "    Candidate(id=\"c3\", text=\"It was another cold morning when Detective Rodriguez found the first clue...\", meta={\"logprobs\": -0.8}),\n",
        "    Candidate(id=\"c4\", text=\"Detective Park had seen many cases, but this one was different...\", meta={\"logprobs\": -0.4}),\n",
        "    Candidate(id=\"c5\", text=\"The phone rang at 3 AM. Detective Thompson knew it was trouble...\", meta={\"logprobs\": -0.2}),\n",
        "]\n",
        "\n",
        "# Step 4: Select the best 3\n",
        "result = selector.step(parent, candidates)\n",
        "\n",
        "# Display results\n",
        "print(\"=\"*60)\n",
        "print(\"BEAM SEARCH RESULTS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nInput: {len(candidates)} candidates\")\n",
        "print(f\"Output: {len(result.kept)} selected (top {beam.k})\\n\")\n",
        "\n",
        "print(\"‚úÖ SELECTED (Top 3 by confidence):\")\n",
        "for i, candidate in enumerate(result.kept, 1):\n",
        "    score = candidate.meta.get('logprobs', 'N/A')\n",
        "    print(f\"\\n{i}. [{candidate.id}] Score: {score}\")\n",
        "    print(f\"   {candidate.text}\")\n",
        "\n",
        "print(f\"\\n‚ùå FILTERED OUT ({len(result.pruned)}):\")\n",
        "for candidate in result.pruned:\n",
        "    score = candidate.meta.get('logprobs', 'N/A')\n",
        "    print(f\"   [{candidate.id}] Score: {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "example2"
      },
      "source": [
        "## Example 2: Multi-Strategy Scoring\n",
        "\n",
        "Instead of just using raw scores, let's combine multiple factors:\n",
        "- **Confidence** (from logprobs)\n",
        "- **Relevance** (semantic similarity to prompt)\n",
        "- **Novelty** (how different from other candidates)\n",
        "\n",
        "This gives us smarter selection!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "example2_code"
      },
      "outputs": [],
      "source": [
        "# Setup embedding provider (for semantic similarity)\n",
        "embedding_provider = DummyEmbeddingProvider(dimension=64, seed=42)\n",
        "\n",
        "# Create a composite scorer with weighted strategies\n",
        "scorer = CompositeScorer(\n",
        "    weights={\n",
        "        \"confidence\": 0.4,  # 40% weight on LLM confidence\n",
        "        \"relevance\": 0.4,   # 40% weight on relevance to prompt\n",
        "        \"novelty\": 0.2,     # 20% weight on being different\n",
        "    },\n",
        "    embedding_provider=embedding_provider\n",
        ")\n",
        "\n",
        "# Create beam with scoring\n",
        "beam = BeamSelector(scorer=scorer, k=3)\n",
        "selector = BranchSelector(beam_selector=beam)\n",
        "\n",
        "# Same candidates as before\n",
        "result = selector.step(parent, candidates)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"MULTI-STRATEGY SCORING RESULTS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nScoring Strategy:\")\n",
        "print(f\"  ‚Ä¢ 40% Confidence (logprobs from LLM)\")\n",
        "print(f\"  ‚Ä¢ 40% Relevance (similarity to prompt)\")\n",
        "print(f\"  ‚Ä¢ 20% Novelty (uniqueness)\\n\")\n",
        "\n",
        "print(\"‚úÖ SELECTED (Top 3 by composite score):\")\n",
        "for i, candidate in enumerate(result.kept, 1):\n",
        "    print(f\"\\n{i}. [{candidate.id}]\")\n",
        "    print(f\"   {candidate.text[:60]}...\")\n",
        "    if hasattr(candidate, 'score'):\n",
        "        print(f\"   Final Score: {candidate.score:.3f}\")\n",
        "\n",
        "print(f\"\\nüí° Notice: Results may differ from Example 1!\")\n",
        "print(f\"   We're now considering relevance and novelty, not just confidence.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "example3"
      },
      "source": [
        "## Example 3: Novelty Filtering (Remove Duplicates)\n",
        "\n",
        "Sometimes LLMs generate similar responses. Let's filter out near-duplicates using:\n",
        "- **Cosine similarity** - Remove responses that are too similar\n",
        "- **MMR (Maximal Marginal Relevance)** - Balance relevance and diversity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "example3_code"
      },
      "outputs": [],
      "source": [
        "# Create candidates with some duplicates\n",
        "candidates_with_dupes = [\n",
        "    Candidate(id=\"c1\", text=\"The sky is blue and beautiful today\", meta={\"logprobs\": -0.2}),\n",
        "    Candidate(id=\"c2\", text=\"The sky is blue and lovely today\", meta={\"logprobs\": -0.3}),  # Very similar to c1\n",
        "    Candidate(id=\"c3\", text=\"Quantum computers use superposition\", meta={\"logprobs\": -0.4}),\n",
        "    Candidate(id=\"c4\", text=\"The weather is nice with blue skies\", meta={\"logprobs\": -0.25}),  # Similar to c1\n",
        "    Candidate(id=\"c5\", text=\"Machine learning enables pattern recognition\", meta={\"logprobs\": -0.35}),\n",
        "]\n",
        "\n",
        "parent = Candidate(id=\"prompt\", text=\"Tell me something interesting\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"NOVELTY FILTERING DEMO\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nInput: {len(candidates_with_dupes)} candidates (some are similar)\\n\")\n",
        "\n",
        "# Method 1: Cosine Similarity Filter\n",
        "print(\"\\nüìä Method 1: COSINE SIMILARITY FILTER\")\n",
        "print(\"   Remove candidates with similarity > 80%\\n\")\n",
        "\n",
        "cosine_filter = CosineNoveltyFilter(\n",
        "    threshold=0.80,  # Remove if 80%+ similar\n",
        "    embedding_provider=embedding_provider\n",
        ")\n",
        "\n",
        "beam_cosine = BeamSelector(scorer=scorer, k=5, novelty_filter=cosine_filter)\n",
        "selector_cosine = BranchSelector(beam_selector=beam_cosine)\n",
        "result_cosine = selector_cosine.step(parent, candidates_with_dupes)\n",
        "\n",
        "print(f\"‚úÖ Kept: {len(result_cosine.kept)} unique responses\")\n",
        "for c in result_cosine.kept:\n",
        "    print(f\"   ‚Ä¢ [{c.id}] {c.text}\")\n",
        "\n",
        "print(f\"\\n‚ùå Filtered: {len(result_cosine.pruned)} duplicates\")\n",
        "for c in result_cosine.pruned:\n",
        "    print(f\"   ‚Ä¢ [{c.id}] {c.text[:50]}... (too similar)\")\n",
        "\n",
        "# Method 2: MMR (Maximal Marginal Relevance)\n",
        "print(\"\\n\\nüìä Method 2: MMR (BALANCED APPROACH)\")\n",
        "print(\"   Balance between relevance (70%) and diversity (30%)\\n\")\n",
        "\n",
        "mmr_filter = MMRNoveltyFilter(\n",
        "    lambda_param=0.7,  # 70% relevance, 30% diversity\n",
        "    embedding_provider=embedding_provider\n",
        ")\n",
        "\n",
        "beam_mmr = BeamSelector(scorer=scorer, k=5, novelty_filter=mmr_filter)\n",
        "selector_mmr = BranchSelector(beam_selector=beam_mmr)\n",
        "result_mmr = selector_mmr.step(parent, candidates_with_dupes)\n",
        "\n",
        "print(f\"‚úÖ Kept: {len(result_mmr.kept)} diverse responses\")\n",
        "for c in result_mmr.kept:\n",
        "    print(f\"   ‚Ä¢ [{c.id}] {c.text}\")\n",
        "\n",
        "print(\"\\nüí° MMR ensures both quality AND diversity!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "example4"
      },
      "source": [
        "## Example 4: Complete Pipeline with Budget Control\n",
        "\n",
        "Let's put it all together with:\n",
        "- ‚úÖ Beam search (top K selection)\n",
        "- ‚úÖ Multi-strategy scoring\n",
        "- ‚úÖ Novelty filtering\n",
        "- ‚úÖ Budget management (prevent runaway costs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "example4_code"
      },
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"COMPLETE PIPELINE EXAMPLE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Setup components\n",
        "embedding_provider = DummyEmbeddingProvider(dimension=64, seed=42)\n",
        "\n",
        "# 1. Scorer: Weighted strategies\n",
        "scorer = CompositeScorer(\n",
        "    weights={\n",
        "        \"confidence\": 0.5,\n",
        "        \"relevance\": 0.3,\n",
        "        \"novelty\": 0.2,\n",
        "    },\n",
        "    embedding_provider=embedding_provider\n",
        ")\n",
        "\n",
        "# 2. Novelty filter: Remove near-duplicates\n",
        "novelty_filter = MMRNoveltyFilter(\n",
        "    lambda_param=0.6,  # 60% relevance, 40% diversity\n",
        "    embedding_provider=embedding_provider\n",
        ")\n",
        "\n",
        "# 3. Budget: Control costs\n",
        "budget = Budget(\n",
        "    max_tokens=10000,    # Stop at 10K tokens\n",
        "    max_nodes=20,        # Max 20 branches explored\n",
        "    max_time_seconds=60  # Max 60 seconds\n",
        ")\n",
        "budget_manager = BudgetManager(budget=budget)\n",
        "\n",
        "# 4. Beam: Top-3 selection\n",
        "beam = BeamSelector(\n",
        "    scorer=scorer,\n",
        "    k=3,\n",
        "    novelty_filter=novelty_filter\n",
        ")\n",
        "\n",
        "# 5. Main selector\n",
        "selector = BranchSelector(\n",
        "    beam_selector=beam,\n",
        "    budget_manager=budget_manager\n",
        ")\n",
        "\n",
        "# Test scenario: Question answering\n",
        "parent = Candidate(\n",
        "    id=\"question\",\n",
        "    text=\"What are the benefits of exercise?\",\n",
        "    meta={\"logprobs\": -0.1}\n",
        ")\n",
        "\n",
        "candidates = [\n",
        "    Candidate(id=\"c1\", text=\"Exercise improves cardiovascular health and reduces disease risk\", meta={\"logprobs\": -0.2}),\n",
        "    Candidate(id=\"c2\", text=\"Regular physical activity boosts heart health and lowers illness\", meta={\"logprobs\": -0.3}),  # Similar to c1\n",
        "    Candidate(id=\"c3\", text=\"Working out enhances mental well-being and reduces stress\", meta={\"logprobs\": -0.25}),\n",
        "    Candidate(id=\"c4\", text=\"Physical fitness increases energy levels and improves sleep quality\", meta={\"logprobs\": -0.35}),\n",
        "    Candidate(id=\"c5\", text=\"Exercise helps with weight management and muscle building\", meta={\"logprobs\": -0.4}),\n",
        "    Candidate(id=\"c6\", text=\"Regular workouts strengthen bones and improve flexibility\", meta={\"logprobs\": -0.45}),\n",
        "]\n",
        "\n",
        "# Run the pipeline\n",
        "result = selector.step(parent, candidates)\n",
        "\n",
        "# Display results\n",
        "print(f\"\\nüìù Question: {parent.text}\")\n",
        "print(f\"\\nüìä Pipeline Configuration:\")\n",
        "print(f\"   ‚Ä¢ Beam Size: Top-3 selection\")\n",
        "print(f\"   ‚Ä¢ Scoring: 50% confidence, 30% relevance, 20% novelty\")\n",
        "print(f\"   ‚Ä¢ Novelty: MMR with 60% relevance balance\")\n",
        "print(f\"   ‚Ä¢ Budget: 10K tokens, 20 nodes, 60 seconds\")\n",
        "\n",
        "print(f\"\\n‚úÖ SELECTED RESPONSES ({len(result.kept)}/{len(candidates)}):\")\n",
        "for i, candidate in enumerate(result.kept, 1):\n",
        "    print(f\"\\n{i}. [{candidate.id}]\")\n",
        "    print(f\"   {candidate.text}\")\n",
        "    if hasattr(candidate, 'score'):\n",
        "        print(f\"   Score: {candidate.score:.3f}\")\n",
        "\n",
        "print(f\"\\n‚ùå FILTERED OUT ({len(result.pruned)}):\")\n",
        "for candidate in result.pruned:\n",
        "    print(f\"   ‚Ä¢ [{candidate.id}] {candidate.text[:50]}...\")\n",
        "\n",
        "# Budget status\n",
        "print(f\"\\nüí∞ Budget Status:\")\n",
        "print(f\"   ‚Ä¢ Tokens used: {budget_manager.tokens_used} / {budget.max_tokens}\")\n",
        "print(f\"   ‚Ä¢ Nodes explored: {budget_manager.nodes_explored} / {budget.max_nodes}\")\n",
        "print(f\"   ‚Ä¢ Within budget: {'‚úÖ Yes' if not budget_manager.is_exhausted() else '‚ùå No'}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ Pipeline complete! High-quality, diverse results.\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "summary"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this demo, you learned:\n",
        "\n",
        "### ‚úÖ What We Covered\n",
        "\n",
        "1. **Basic Beam Search** - Select top-K responses\n",
        "2. **Multi-Strategy Scoring** - Combine confidence, relevance, novelty\n",
        "3. **Novelty Filtering** - Remove duplicates and ensure diversity\n",
        "4. **Complete Pipeline** - Production-ready setup with budget control\n",
        "\n",
        "### üéØ Key Components\n",
        "\n",
        "| Component | Purpose |\n",
        "|-----------|----------|\n",
        "| `BranchSelector` | Main orchestrator |\n",
        "| `BeamSelector` | Top-K selection |\n",
        "| `CompositeScorer` | Multi-strategy scoring |\n",
        "| `NoveltyFilter` | Diversity control |\n",
        "| `BudgetManager` | Cost control |\n",
        "\n",
        "### üìö Next Steps\n",
        "\n",
        "Ready to dive deeper?\n",
        "\n",
        "1. **Advanced Demo**: Check out the [Creative Writing Demo](https://colab.research.google.com/github/chatroutes/chatroutes-autobranch/blob/master/notebooks/creative_writing_colab.ipynb)\n",
        "   - Full end-to-end example with Ollama\n",
        "   - Real LLM integration\n",
        "   - Multi-turn branching\n",
        "\n",
        "2. **Documentation**:\n",
        "   - [GitHub Repository](https://github.com/chatroutes/chatroutes-autobranch)\n",
        "   - [Quick Start Guide](https://github.com/chatroutes/chatroutes-autobranch/blob/master/QUICKSTART.md)\n",
        "   - [Examples](https://github.com/chatroutes/chatroutes-autobranch/tree/master/examples)\n",
        "\n",
        "3. **Use Cases**:\n",
        "   - Tree-of-thought reasoning\n",
        "   - Multi-agent systems\n",
        "   - Creative writing assistants\n",
        "   - Question answering systems\n",
        "   - Code generation with multiple solutions\n",
        "\n",
        "### üí° Pro Tips\n",
        "\n",
        "- Start with simple beam search, add complexity as needed\n",
        "- Use MMR for best balance of quality and diversity\n",
        "- Always set budgets to prevent runaway costs\n",
        "- Experiment with different scoring weights for your use case\n",
        "\n",
        "---\n",
        "\n",
        "### üöÄ Install in Your Project\n",
        "\n",
        "```bash\n",
        "pip install chatroutes-autobranch\n",
        "```\n",
        "\n",
        "### üìß Get Help\n",
        "\n",
        "- **Issues**: https://github.com/chatroutes/chatroutes-autobranch/issues\n",
        "- **Discussions**: https://github.com/chatroutes/chatroutes-autobranch/discussions\n",
        "- **Email**: hello@chatroutes.com\n",
        "\n",
        "---\n",
        "\n",
        "**Happy branching!** üå≥"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ChatRoutes AutoBranch - Getting Started Demo",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
